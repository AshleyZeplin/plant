{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import libraries \n",
    "Step 2: Read in dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Initialize the Dataset [def __init__()]\n",
    "    Initializes the dataset before the images are loaded to set up all the important components that willbe used later in that class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__ (self, root: str, split: str, transform=None):\n",
    "\n",
    "#self: makes sure each object stores its own data(self.root, self.split, self.transform are accessible through the class)\n",
    "#root: dataset folder (path to plant_village_dataset from step 2)\n",
    "#:str - string\n",
    "#split: whether this is a train, test, or validation dataset\n",
    "#transorm: any image transformation, but this only happens one time so we want it somewhere where there is a loop \n",
    "\n",
    "    self.root = root #know where the images are stored, allows flexibility to change the path easily without modifying the class \n",
    "    self.species = os.listdir(self.root) #automatically find all available species(different plant species), \n",
    "    self.img_split = split #seperates training, testing,validation data to ensure it loads the correct images from each \n",
    "    self.transform = transform #stores any image transformation,  ensures images are correctly formatted for the model \n",
    "    self. fata = self.__load_files() #collects all image file paths/ allows efficient data retrieval for training\n",
    "\n",
    "    unique_labels = sorted(set(f\"{species}_{disease}\" for _,species, disease in self.data))\n",
    "# goes through all the images stored in self.data and extracts unique species + disease labels \n",
    "# uses set() to remove duplicates \n",
    "# sorts them alphabetically so the mapping is consistent \n",
    "# creates a list of all possible class labels \n",
    "# ensures labels always have the same order -> \"Tomato_BacterialSpot\" is always 0, \"Potato_EarlyBlight\" is always 1 \n",
    "    self.label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "# takes  alist of unique labels and assigns each label a unique number (starting from 0)\n",
    "# enumerate(): assigns index numbers \n",
    "# Why? Neural networks can't understand text labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Get Dataset Size[def__len__()]\n",
    "    To return the number of images in the dataset - PyTorch DataLoaders need this toknow how many batches to create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return len(self.data)\n",
    "#counts how many images are available toknow how many samples exist to create batches (wouldn't know when to stop loading data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Get an Image & Label [__getitem__()]\n",
    "    Controls how each image and label is loaded, processed, and returned\n",
    "    When a PyTorch DataLoader requests a batch, it calls __getitem__for each item to get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1988999585.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    if self.transform: img = self.transform(img\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def __getitem__(self,idx):\n",
    "\n",
    "#Retrieves an image and label from the dataset based on an index (idx)\n",
    "#Converts the label into a numerical format for the model\n",
    "\n",
    "    img_file, species,disease_class = self.data[idx] #fetches the idx-th image filepath and its species + disease label/ ensures each omage has a corresponding label\n",
    "    img = Image.open(img_file).convert(\"RGB\") # opens the image file from img_file and converts it to RGB format / prevents grayscale images \n",
    "\n",
    "    if self.transform: img = self.transform(img) # applies transformations / converts to PyTorch tensor\n",
    "\n",
    "    label = self.label_map[f\"{species}_{disease_class}\"] # uses self.label_map to convert species + disease into a number \n",
    "    label = torch.tensor(label, dtype=torch.long) # converts the numeric label into a PyTorch tensor \n",
    "        # dtype=torch.long: ensures the label is in integer format\n",
    "\n",
    "    return img, label # returns the processedimage and label / Dataloader collects images and labels in batches \n",
    "        # model expects data in this format (image_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Collect all Image File Paths [def __load_files()]\n",
    "    Scanning the dataset directory and collecting allimage file paths along with their species and disease labels \n",
    "    Ensures the dataset is properly structured before training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_files(self):\n",
    "    #Creates a list of all image file paths and tehir corresponding labels \n",
    "    #Organizes images by species and disease\n",
    "    #Ensures hiddenm giles and non-image are ignored \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
